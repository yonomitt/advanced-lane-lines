{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Lane Finding Project\n",
    "\n",
    "The goals / steps of this project are the following:\n",
    "- Compute the camera calibration matrix and distortion coefficients given a set of chessboard images.\n",
    "- Apply a distortion correction to raw images.\n",
    "- Use color transforms, gradients, etc., to create a thresholded binary image.\n",
    "- Apply a perspective transform to rectify binary image (\"birds-eye view\").\n",
    "- Detect lane pixels and fit to find the lane boundary.\n",
    "- Determine the curvature of the lane and vehicle position with respect to center.\n",
    "- Warp the detected lane boundaries back onto the original image.\n",
    "- Output visual display of the lane boundaries and numerical estimation of lane curvature and vehicle position.\n",
    "\n",
    "---\n",
    "\n",
    "## 0. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Camera Calibration\n",
    "\n",
    "Camera calibration only needs to occur once, but I have put it in a function to encourage good coding behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def find_checkerboard_corners(img, nx, ny):\n",
    "    \"\"\"Helper function to detect the internal corners of an image of a checkerboard\n",
    "    \n",
    "    Parameters:\n",
    "        • img - image of a checkerboard\n",
    "        • nx - number of internal checkerboard corners in the x direction\n",
    "        • ny - number of internal checkerboard corners in the y direction\n",
    "        \n",
    "    Returns:\n",
    "        A list of corners\"\"\"\n",
    "    \n",
    "    # openCV reads in images BGR (instead of RGB)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Find the chess board corners\n",
    "    ret, corners = cv2.findChessboardCorners(gray, (nx, ny), None)\n",
    "    \n",
    "    if ret:\n",
    "        return corners\n",
    "    \n",
    "    return []\n",
    "\n",
    "\n",
    "def camera_calibration(img_files, nx=9, ny=6):\n",
    "    \"\"\"Calibrate the camera based on several checkerboard images taken.\n",
    "    \n",
    "    Parameters:\n",
    "        • img_files - list of checkboard image files, ideally taken from different angles and distances\n",
    "        • nx - number of internal checkerboard corners in the x direction for all images\n",
    "        • ny - number of internal checkerboard corners in the y direction for all images\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of the camera matrix and the distortion coefficients\"\"\"\n",
    "    \n",
    "    # prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "    objp = np.zeros((ny * nx, 3), np.float32)\n",
    "    objp[:,:2] = np.mgrid[0:nx, 0:ny].T.reshape(-1,2)\n",
    "    \n",
    "    # Arrays to store object points and image points from all the images.\n",
    "    objpoints = [] # 3d point in real world space\n",
    "    imgpoints = [] # 2d points in image plane.\n",
    "\n",
    "    for idx, img_file in enumerate(img_files):\n",
    "        img = cv2.imread(img_file)\n",
    "        \n",
    "        # find the checkerboard corners\n",
    "        corners = find_checkerboard_corners(img, nx, ny)\n",
    "\n",
    "        # If found, add object points, image points (after refining them)\n",
    "        if len(corners):\n",
    "            objpoints.append(objp)\n",
    "            imgpoints.append(corners)\n",
    "    \n",
    "    img_size = (img.shape[1], img.shape[0])\n",
    "    \n",
    "    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, img_size, None, None)\n",
    "    \n",
    "    return (mtx, dist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img_files = glob.glob('camera_cal/*.jpg')\n",
    "mtx, dist = camera_calibration(img_files)\n",
    "\n",
    "img_file = img_files[13]\n",
    "\n",
    "img = cv2.imread(img_file)\n",
    "cv2.imwrite('output_images/01-checkerboard-orig.jpg', img)\n",
    "\n",
    "plt.title('Original Image of a Checkerboard')\n",
    "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "corners = find_checkerboard_corners(img, 9, 6)\n",
    "cv2.drawChessboardCorners(img, (9, 6), corners, True)\n",
    "cv2.imwrite('output_images/02-checkerboard-corners.jpg', img)\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.title('Detected Corners on a Checkerboard')\n",
    "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB));\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Undistort\n",
    "\n",
    "This will need to be run on all images produced by the camera that was calibrated in the previous step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def undistort(img, mtx, dist):\n",
    "    \"\"\"Undistort an image using the camera matrix and the distorition coefficients returned by the 'camera_alibration'\n",
    "    function\n",
    "    \n",
    "    Parameters:\n",
    "        • img - image that needs to be undistorted\n",
    "        • mtx - camera matrix\n",
    "        • dist - distortion coefficients\n",
    "        \n",
    "    Returns:\n",
    "        An undistorted image\"\"\"\n",
    "    \n",
    "    img_size = (img.shape[1], img.shape[0])\n",
    "    undist = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "    return undist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img = cv2.imread(img_files[13])\n",
    "\n",
    "plt.title('Original Image of a Checkerboard')\n",
    "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "img = undistort(img, mtx, dist)\n",
    "cv2.imwrite('output_images/03-checkerboard-undistorted.jpg', img)\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.title(\"Undistorted Image\")\n",
    "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "undistort_imgs = []\n",
    "file_bases = [f.split('/')[-1][:-4] for f in glob.glob('test_images/*.jpg')]\n",
    "\n",
    "for filename, file_base in zip(glob.glob('test_images/*.jpg'), file_bases):\n",
    "    \n",
    "    orig_img = cv2.imread(filename)\n",
    "    cv2.imwrite('output_images/{}-orig-00.jpg'.format(file_base), orig_img)\n",
    "    \n",
    "    undistort_img = undistort(orig_img, mtx, dist)\n",
    "    cv2.imwrite('output_images/{}-undist-01.jpg'.format(file_base), undistort_img)\n",
    "\n",
    "    undistort_imgs.append(undistort_img)\n",
    "    \n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,10))\n",
    "    ax1.set_title('Original Image')\n",
    "    ax1.imshow(cv2.cvtColor(orig_img, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "    ax2.set_title('Undistorted Image')\n",
    "    ax2.imshow(cv2.cvtColor(undistort_img, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Thresholding functions\n",
    "\n",
    "Various thresholding functions determine lane boundries. To make the algorithm more robust, these will be combined together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def absolute_sobel_threshold(img, orient='x', sobel_kernel=3, thresh=(0, 255)):\n",
    "\n",
    "    \"\"\"Creates a binary image based on the gradient ine one direction of the input image.\n",
    "    \n",
    "    This function uses the Sobel operator to calculate the derivative.\n",
    "    \n",
    "    Parameters:\n",
    "        • img - input image\n",
    "        • orient - direction to take the derivative ('x' or 'y')\n",
    "        • sobel_kernel - an odd number to define the size of the Sobel kernel\n",
    "        • thresh - tuple of low and high thresholds to be included in the output binary\n",
    "        \n",
    "    Returns:\n",
    "        A single channel binary image of detected edges in the original image\"\"\"\n",
    "    \n",
    "    # 1) Convert to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # 2) Take the derivative in x or y given orient = 'x' or 'y'\n",
    "    filter_type = (orient == 'x', orient == 'y')\n",
    "    sobel = cv2.Sobel(gray, cv2.CV_64F, *filter_type, ksize=sobel_kernel)\n",
    "\n",
    "    # 3) Take the absolute value of the derivative or gradient\n",
    "    abs_sobel = np.absolute(sobel)\n",
    "\n",
    "    # 4) Scale to 8-bit (0 - 255) then convert to type = np.uint8\n",
    "    scaled_sobel = np.uint8(255 * abs_sobel / np.max(abs_sobel))\n",
    "\n",
    "    # 5) Create a mask of 1's where the scaled gradient meets the thresholds \n",
    "    grad_binary = np.zeros_like(scaled_sobel)\n",
    "    grad_binary[(scaled_sobel >= thresh[0]) & (scaled_sobel <= thresh[1])] = 1\n",
    "\n",
    "    # 6) Return this mask as your binary_output image\n",
    "    return grad_binary\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def magnitude_threshold(img, sobel_kernel=3, mag_thresh=(0, 255)):\n",
    "\n",
    "    \"\"\"Creates a binary image based on the overal magnitude of the gradient of the input image.\n",
    "    \n",
    "    This function uses the Sobel operator to calculate the derivative.\n",
    "    \n",
    "    Parameters:\n",
    "        • img - input image\n",
    "        • sobel_kernel - an odd number to define the size of the Sobel kernel\n",
    "        • thresh - tuple of low and high thresholds to be included in the output binary\n",
    "        \n",
    "    Returns:\n",
    "        A single channel binary image of detected edges in the original image\"\"\"\n",
    "\n",
    "    # 1) Convert to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # 2) Take the gradient in x and y separately\n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "\n",
    "    # 3) Calculate the magnitude \n",
    "    abs_sobelxy = (sobelx ** 2 + sobely ** 2) ** 0.5\n",
    "\n",
    "    # 4) Scale to 8-bit (0 - 255) and convert to type = np.uint8\n",
    "    scaled_sobel = np.uint8(255 * abs_sobelxy / np.max(abs_sobelxy))\n",
    "\n",
    "    # 5) Create a binary mask where mag thresholds are met\n",
    "    mag_binary = np.zeros_like(scaled_sobel)\n",
    "    mag_binary[(scaled_sobel >= mag_thresh[0]) & (scaled_sobel <= mag_thresh[1])] = 1\n",
    "\n",
    "    # 6) Return this mask as your binary_output image\n",
    "    return mag_binary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def direction_threshold(img, sobel_kernel=3, thresh=(0, np.pi/2)):\n",
    "\n",
    "    \"\"\"Creates a binary image based on the gradient direction of the input image.\n",
    "    \n",
    "    This function uses the Sobel operator to calculate the derivative.\n",
    "    \n",
    "    Parameters:\n",
    "        • img - input image\n",
    "        • sobel_kernel - an odd number to define the size of the Sobel kernel\n",
    "        • thresh - tuple of low and high thresholds to be included in the output binary\n",
    "        \n",
    "    Returns:\n",
    "        A single channel binary image of detected edges in the original image\"\"\"\n",
    "\n",
    "    # 1) Convert to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # 2) Take the gradient in x and y separately\n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "\n",
    "    # 3) Take the absolute value of the x and y gradients\n",
    "    abs_sobelx = np.absolute(sobelx)\n",
    "    abs_sobely = np.absolute(sobely)\n",
    "\n",
    "    # 4) Use np.arctan2(abs_sobely, abs_sobelx) to calculate the direction of the gradient \n",
    "    direction = np.arctan2(abs_sobely, abs_sobelx)\n",
    "\n",
    "    # 5) Create a binary mask where direction thresholds are met\n",
    "    dir_binary = np.zeros_like(direction)\n",
    "    dir_binary[(direction >= thresh[0]) & (direction <= thresh[1])] = 1\n",
    "\n",
    "    # 6) Return this mask as your binary_output image\n",
    "    return dir_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def saturation_threshold(img, thresh=(0, 255)):\n",
    "    \n",
    "    \"\"\"Creates a binary image based on the saturation channel of the input image converted to HLS color space.\n",
    "        \n",
    "    Parameters:\n",
    "        • img - input image\n",
    "        • thresh - tuple of low and high thresholds to be included in the output binary\n",
    "        \n",
    "    Returns:\n",
    "        A thresholded single channel binary image of the original image\"\"\"\n",
    "\n",
    "    # 1) Convert to HLS color space\n",
    "    hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "\n",
    "    # 2) Apply a threshold to the S channel\n",
    "    s = hls[:, :, 2]\n",
    "    sat_binary = np.zeros_like(s)\n",
    "    sat_binary[(s > thresh[0]) & (s <= thresh[1])] = 1\n",
    "\n",
    "    # 3) Return a binary image of threshold result\n",
    "    return sat_binary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def threshold(img):\n",
    "    \n",
    "    \"\"\"Creates a binary image based on combining various thresholding techniques.\n",
    "    \n",
    "    Paramters:\n",
    "        • img - input image\n",
    "        \n",
    "    Returns:\n",
    "        A binary image where the lane markers are clearly visible\"\"\"\n",
    "    \n",
    "    ksize = 5\n",
    "    \n",
    "    gradx = absolute_sobel_threshold(img, orient='x', sobel_kernel=ksize, thresh=(20, 100))\n",
    "    grady = absolute_sobel_threshold(img, orient='y', sobel_kernel=ksize, thresh=(20, 100))\n",
    "    mag_binary = magnitude_threshold(img, sobel_kernel=ksize, mag_thresh=(20, 100))\n",
    "    dir_binary = direction_threshold(img, sobel_kernel=ksize, thresh=(0.7, 1.3))\n",
    "    \n",
    "    sat_binary = saturation_threshold(img, thresh=(90, 255))\n",
    "\n",
    "    combined = np.zeros_like(dir_binary)\n",
    "    combined[(((gradx == 1) & (grady == 1)) | ((mag_binary == 1) & (dir_binary == 1))) | (sat_binary == 1)] = 1\n",
    "\n",
    "    return combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "thresholded_imgs = []\n",
    "\n",
    "for undistort_img, file_base in zip(undistort_imgs, file_bases):\n",
    "\n",
    "    thresholded_img = threshold(undistort_img)\n",
    "    cv2.imwrite('output_images/{}-thresh-02.jpg'.format(file_base), thresholded_img)\n",
    "    \n",
    "    thresholded_imgs.append(thresholded_img)\n",
    "    \n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,10))\n",
    "    ax1.set_title('Undistorted Image')\n",
    "    ax1.imshow(cv2.cvtColor(undistort_img, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "    ax2.set_title('Thresholded Image')\n",
    "    ax2.imshow(thresholded_img, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "---\n",
    "\n",
    "## 4. Perspective Transformation\n",
    "\n",
    "These functions will transform images from perspective view to birds-eye view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transform_birdseye(img):\n",
    "    \n",
    "    \"\"\"Applies a transformation to warp an image. The result is a birds-eye view of the lane.\n",
    "    \n",
    "    Parameters:\n",
    "        • img - input image of the lane\n",
    "        \n",
    "    Returns:\n",
    "        A birds-eye view image of the lane\"\"\"\n",
    "    \n",
    "    # define the source and destination points for the desired transformation\n",
    "    src = np.float32([[190, 720], [596, 446], [692, 446], [1140, 720]])    \n",
    "    dst = np.float32([[190, 720], [190, 0], [1140, 0], [1140, 720]])\n",
    "    \n",
    "    # get the transform matrix\n",
    "    M = cv2.getPerspectiveTransform(src, dst)\n",
    "    \n",
    "    # get the image size\n",
    "    img_size = (img.shape[1], img.shape[0])\n",
    "    \n",
    "    # warp the image\n",
    "    warped = cv2.warpPerspective(img, M, img_size, flags=cv2.INTER_LINEAR)\n",
    "    \n",
    "    return warped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "birdseye_imgs = []\n",
    "\n",
    "for thresholded_img, file_base in zip(thresholded_imgs, file_bases):\n",
    "\n",
    "    birdseye_img = transform_birdseye(thresholded_img)\n",
    "    cv2.imwrite('output_images/{}-warp-03.jpg'.format(file_base), birdseye_img)\n",
    "    \n",
    "    birdseye_imgs.append(thresholded_img)\n",
    "    \n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,10))\n",
    "    ax1.set_title('Thresholded Image')\n",
    "    ax1.imshow(thresholded_img, cmap='gray')\n",
    "\n",
    "    ax2.set_title('Birds-Eye Warped Image')\n",
    "    ax2.imshow(birdseye_img, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
